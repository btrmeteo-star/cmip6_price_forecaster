#!/usr/bin/env python3
"""
ä½¿ç”¨ MLflow è®­ç»ƒ CMIP6 å†œäº§å“ä»·æ ¼é¢„æµ‹æ¨¡å‹ï¼ˆå«æ»åç‰¹å¾ï¼‰
- è¾“å…¥: data/final/{crop}_dataset.csvï¼ˆç”± data_merge.py ç”Ÿæˆï¼‰
- ç‰¹å¾: tas_avg, pr_sum + æ»åé¡¹ (lag1, lag7)
- æ¨¡å‹: LinearRegression, RandomForest, XGBoost
- è¾“å‡º: MLflow å®éªŒè®°å½•ï¼ˆhttp://localhost:8000ï¼‰
"""

import os
from pathlib import Path
import pandas as pd
import numpy as np
import mlflow
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from xgboost import XGBRegressor

# === é…ç½® ===
PROJECT_ROOT = Path(__file__).resolve().parents[1]
FINAL_DIR = PROJECT_ROOT / "data" / "final"
CROPS = ["rice", "corn", "barley"]

# MLflow è®¾ç½®
mlflow.set_tracking_uri("http://0.0.0.0:8000")
EXPERIMENT_NAME = "cmip6-crop-price-prediction"

# ç‰¹å¾åˆ—ï¼ˆå¿…é¡»ä¸ data_merge.py ç”Ÿæˆçš„ä¸€è‡´ï¼‰
FEATURE_COLS = [
    "tas_avg", "pr_sum",
    "tas_lag1", "pr_lag1", "price_lag1",
    "tas_lag7", "pr_lag7", "price_lag7"
]

def train_and_log(crop: str, model_name: str, model, X_train, X_test, y_train, y_test):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹å¹¶è®°å½•åˆ° MLflow"""
    with mlflow.start_run(run_name=f"{crop}-{model_name}"):
        # æ ‡ç­¾
        mlflow.set_tag("crop", crop)
        mlflow.set_tag("model_type", model_name)

        # è®­ç»ƒ
        model.fit(X_train, y_train)

        # é¢„æµ‹
        y_pred = model.predict(X_test)

        # è¯„ä¼°æŒ‡æ ‡
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))

        # è®°å½•æŒ‡æ ‡
        mlflow.log_metric("r2", r2)
        mlflow.log_metric("mae", mae)
        mlflow.log_metric("rmse", rmse)

        # è®°å½•è¶…å‚æ•°
        if model_name == "random_forest":
            mlflow.log_param("n_estimators", model.n_estimators)
            mlflow.log_param("max_depth", model.max_depth)
        elif model_name == "xgboost":
            mlflow.log_param("n_estimators", model.n_estimators)
            mlflow.log_param("learning_rate", model.learning_rate)

        # ä¿å­˜æ¨¡å‹
        mlflow.sklearn.log_model(model, "model")

        print(f"âœ… {crop} - {model_name}: RÂ²={r2:.4f}, MAE={mae:.2f}, RMSE={rmse:.2f}")

def main():
    # åˆ›å»ºæˆ–è·å– MLflow å®éªŒ
    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
    if experiment is None:
        mlflow.create_experiment(EXPERIMENT_NAME)
    mlflow.set_experiment(EXPERIMENT_NAME)

    for crop in CROPS:
        print(f"\n--- è®­ç»ƒ {crop} æ¨¡å‹ ---")
        dataset_path = FINAL_DIR / f"{crop}_dataset.csv"

        if not dataset_path.exists():
            print(f"âš ï¸  æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}ï¼Œè·³è¿‡...")
            continue

        # åŠ è½½æ•°æ®
        df = pd.read_csv(dataset_path, parse_dates=["date"])
        print(f"ğŸ“Š åŠ è½½ {len(df)} è¡Œæ•°æ®")

        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        X = df[FEATURE_COLS].fillna(0)  # å¤„ç†å¯èƒ½çš„ NaN
        y = df["price"]

        # æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆå‰80%è®­ç»ƒï¼Œå20%æµ‹è¯•ï¼‰
        split_idx = int(0.8 * len(df))
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        # å®šä¹‰æ¨¡å‹
        models = {
            "linear_regression": LinearRegression(),
            "random_forest": RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42
            ),
            "xgboost": XGBRegressor(
                n_estimators=100,
                learning_rate=0.1,
                random_state=42,
                verbosity=0  # é™é»˜æ¨¡å¼
            ),
        }

        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        for name, model in models.items():
            train_and_log(crop, name, model, X_train, X_test, y_train, y_test)

    print("\nğŸ‰ æ‰€æœ‰è®­ç»ƒå®Œæˆï¼æŸ¥çœ‹ MLflow: http://localhost:8000")

if __name__ == "__main__":
    main()
